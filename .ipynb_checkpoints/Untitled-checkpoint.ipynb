{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-6d79f5a8e9c8>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6d79f5a8e9c8>\"\u001b[1;36m, line \u001b[1;32m48\u001b[0m\n\u001b[1;33m    training_set = train_datagen.flow_from_directory('C:\\Users\\agarw\\AI\\14_LeafDiseaseDetection\\Dataset\\train',\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "#initialize nn\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#basic cnn\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(128,128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(25, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = None,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/agarw/AI/14_LeafDiseaseDetection/Dataset/train',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "#print(test_datagen);\n",
    "labels = (training_set.class_indices)\n",
    "print(labels)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/agarw/AI/14_LeafDiseaseDetection/Dataset/val',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "labels2 = (test_set.class_indices)\n",
    "print(labels2)\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 375,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 125)\n",
    "\n",
    "\n",
    "model_json=model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "    model.save_weights(\"model1.h5\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
